# -*- coding: utf-8 -*-
"""ML Exam 3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18QuZiG8gR_-uxSQ2NXEgbD-dHB1Fxipk
"""

import numpy as np
import matplotlib.pyplot as plt
import copy
import sys

# Generate data of same class. Class is the last column
def generateData( size, mean, sigma, className ):
  Y = np.array( [ np.repeat( className, size ) ])
  for i in range( len(mean) ):
    new_X = np.array( [ np.random.normal( mean[i], sigma, size ) ] )
    if i == 0:
      X = new_X
    else:
      X = np.append( X, new_X , axis = 0 )
  X = np.append( X, Y, axis = 0 )
  return X.T


def generateMyDataSet( myObject, splitRatio = 0.2, plot = False ):

  for i in range( len(myObject) ):
    new_X = generateData( myObject[i]["size"], myObject[i]["center"], myObject[i]["variance"], myObject[i]["class"] )
    if i == 0:
      X = new_X
    else:
      X = np.append( X, new_X, axis = 0 )
    if plot == True:
      plt.subplot(3, 4, 1)
      plt.title('Initial Data')
      plt.scatter( new_X[:, 0], new_X[:, 1] )
  
  # Shuffling the data
  np.random.shuffle(X)
  N, M = np.shape( X )
  X, Y  = X[ : , :M-1 ], X[ : , M-1].reshape(-1,1)

  return X, Y

  # Split to train and test set
  N, M = np.shape( X )
  splitIndex = int(splitRatio * N)
  X_test,  Y_test  = X[ 0:splitIndex , :M-1 ], X[ 0:splitIndex , M-1]
  X_train, Y_train = X[ splitIndex: , :M-1 ], X[ splitIndex: , M-1]


  return X_train, Y_train, X_test, Y_test


def normalize( X ):
  meanX = np.mean( X, axis = 0 )
  stdX = np.std( X, axis = 0 )
  newX = ( X - meanX ) / stdX
  return newX


# Returns euclidean distance
def distance(pts, centroidPt):
  return ( np.sum( (pts - centroidPt)**2, axis = 1, keepdims = True ) ) ** 0.5

def getMyClass(Y):
  N, M = np.shape( Y )
  classes = dict()
  for i in range( N ):
    className = str( Y[i, 0] )
    if className not in classes:
      classes[ className ] = 0
    classes[ className ] += 1

  maxCount = 0
  maxClass = None
  for className in classes:
    if classes[ className ] > maxCount:
      maxCount = classes[ className ]
      maxClass = className
  
  return maxClass

def kmeans( X, Y, k = 3, plot = False, initCentroidsRandom = False ):
  
  change = 1
  threshold = 0.01
  X_N, X_M = np.shape( X )
  centroids = X[:k,:]
  if initCentroidsRandom:
    centroids = np.random.random( (k, X_M) )
  prev = np.ones( (X_N, 1) )

  iteration_index = 0
  while( True ):
    if change < threshold: break

    data = []
    p_centroids = copy.deepcopy(centroids)
    # Find distance with respect to all k centroids
    dist = distance( X, centroids[0, :] )
    for i in range( k-1 ):
      dist = np.append( dist, distance( X, centroids[i+1, :] ), axis = 1 )

    # Find the nearest k point
    nearestCentroid = np.argmin( dist, axis = 1 ).reshape(-1, 1)
    
    # Check the difference with previous set
    diff = prev == nearestCentroid
    prev = nearestCentroid
    myTrues = X_N - np.sum( diff )
    
    change = (myTrues / X_N)
    # print("Find points for each cluster:")
    for i in range( k ):
      myClusterPoints = X[ np.where( nearestCentroid == i )[0], : ]
      N, M = np.shape( myClusterPoints )
      if N > 0:
        centroids[i, :] = np.mean( myClusterPoints, axis = 0, keepdims=True )

        data.append({
            "centroid": p_centroids[i,:],
            "pts": myClusterPoints,
            "class": getMyClass( Y[ np.where( nearestCentroid == i )[0], : ] )
        })
      
    iteration_index += 1
    if plot == True and iteration_index < 6:
      plt.subplot(3, 4, iteration_index+1 )
      for c in data:
        plt.title('Iteration: '+ str(iteration_index) )
        plt.scatter( c["pts"][:, 0], c["pts"][:, 1] )
        plt.scatter( c["centroid"][0], c["centroid"][1], color = "black")

  return data

def accuracy( confusion_matrix ):
  return np.sum(np.trace(confusion_matrix))/np.sum(confusion_matrix)

def predict( X, Y, centroids_data ):

  N, M = np.shape( Y )
  classes = []
  for i in range( N ):
    if Y[i, 0] not in classes:
      classes.append( Y[i, 0] )
  
  confusion_matrix = np.zeros( ( len(classes), len(classes) ), dtype=int )

  for i in range( N ):
    actual_class = int( Y[i, 0] ) 

    minDistance = float( 'inf' )
    predicted_class = None
    for className in centroids_data:
      point = np.array( [ X[i,:] ] )
      centroid = np.array( [ className["centroid"] ] )
      dist = distance( point, centroid )[0][0]
      if( dist < minDistance ):
        minDistance = dist
        predicted_class = int( float( className["class"] ) )
    
    confusion_matrix[ actual_class - 1 ][ predicted_class - 1 ] += 1

  return confusion_matrix

def findObjectiveFunctionValue( centroids_data ):
  output = 0
  for c in centroids_data:
    output += np.sum( distance( c["pts"],  c["centroid"] ) )
  return output

# 3B. Sigma = 2

print("************** 3B. PartA - Sigma = 2 ****************")
classes = [
  {
      "center": [ 3, 5 ],
      "variance": 2,
      "class" : 1,
      "size": 100
  },
  {
      "center": [ -5, 2 ],
      "variance": 2,
      "class" : 2,
      "size": 100
  },
  {
      "center": [ 1, -4 ],
      "variance": 2,
      "class" : 3,
      "size": 100
  }
]

plt.figure(figsize=(15,20))
X, Y = generateMyDataSet( classes, plot = True )

for i in range( 10 ):
  data = kmeans( X, Y, k = 3, plot = False )
  print("********************")
  print("K-means n Time: " + str( i ) )
  plt.subplot( 3, 4, i+2 )
  for c in data:
    print("Centroid: " + str( c["centroid"] ) )
    print("Points Count: " + str( np.shape( c["pts"] )[0] ) )
    print("Class: " + str( c["class"] ) )
    print("-------------------")

    plt.title( str(i+1) + ". 3-means " )
    plt.scatter( c["pts"][:, 0], c["pts"][:, 1] )
    plt.scatter( c["centroid"][0], c["centroid"][1], color = "black")

plt.show()
# 3B. Sigma = 4

print("************** 3B. PartA - Sigma = 4 ****************")
classes = [
  {
      "center": [ 3, 5 ],
      "variance": 4,
      "class" : 1,
      "size": 100
  },
  {
      "center": [ -5, 2 ],
      "variance": 4,
      "class" : 2,
      "size": 100
  },
  {
      "center": [ 1, -4 ],
      "variance": 4,
      "class" : 3,
      "size": 100
  }
]

plt.figure(figsize=(15,20))
X, Y = generateMyDataSet( classes, plot = True )

for i in range( 10 ):
  data = kmeans( X, Y, k = 3, plot = False )
  print("********************")
  print("K-means n Time: " + str( i ) )
  plt.subplot( 3, 4, i+2 )
  for c in data:
    print("Centroid: " + str( c["centroid"] ) )
    print("Points Count: " + str( np.shape( c["pts"] )[0] ) )
    print("Class: " + str( c["class"] ) )
    print("-------------------")

    plt.title( str(i+1) + ". 3-means " )
    plt.scatter( c["pts"][:, 0], c["pts"][:, 1] )
    plt.scatter( c["centroid"][0], c["centroid"][1], color = "black")


plt.show()